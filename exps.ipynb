{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80707a1-2f16-4bd2-8774-bcc3b6347ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gp import *\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2a0dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gp' from 'c:\\\\Users\\\\Yue\\\\userDoc\\\\7 code\\\\Python\\\\advml\\\\conditional-marginal-likelihood-sequence\\\\gp.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import gp\n",
    "importlib.reload(gp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4f9b2",
   "metadata": {},
   "source": [
    "**Dataset characteristics**<br>\n",
    "- instant: record index<br>\n",
    "- dteday : date\n",
    "- season : season (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "- yr : year (0: 2011, 1:2012)\n",
    "- mnth : month (1 to 12)\n",
    "- hr : hour (0 to 23)\n",
    "- holiday : whether day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "- weekday : day of the week\n",
    "- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "+ weathersit : \n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n",
    "- atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n",
    "- hum: Normalized humidity. The values are divided to 100 (max)\n",
    "- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "- casual: count of casual users\n",
    "- registered: count of registered users\n",
    "- cnt: count of total rental bikes including both casual and registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ccf28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>17375</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>17376</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>17377</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>17378</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>17379</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "0            1  2011-01-01       1   0     1   0        0        6   \n",
       "1            2  2011-01-01       1   0     1   1        0        6   \n",
       "2            3  2011-01-01       1   0     1   2        0        6   \n",
       "3            4  2011-01-01       1   0     1   3        0        6   \n",
       "4            5  2011-01-01       1   0     1   4        0        6   \n",
       "...        ...         ...     ...  ..   ...  ..      ...      ...   \n",
       "17374    17375  2012-12-31       1   1    12  19        0        1   \n",
       "17375    17376  2012-12-31       1   1    12  20        0        1   \n",
       "17376    17377  2012-12-31       1   1    12  21        0        1   \n",
       "17377    17378  2012-12-31       1   1    12  22        0        1   \n",
       "17378    17379  2012-12-31       1   1    12  23        0        1   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "0               0           1  0.24  0.2879  0.81     0.0000       3   \n",
       "1               0           1  0.22  0.2727  0.80     0.0000       8   \n",
       "2               0           1  0.22  0.2727  0.80     0.0000       5   \n",
       "3               0           1  0.24  0.2879  0.75     0.0000       3   \n",
       "4               0           1  0.24  0.2879  0.75     0.0000       0   \n",
       "...           ...         ...   ...     ...   ...        ...     ...   \n",
       "17374           1           2  0.26  0.2576  0.60     0.1642      11   \n",
       "17375           1           2  0.26  0.2576  0.60     0.1642       8   \n",
       "17376           1           1  0.26  0.2576  0.60     0.1642       7   \n",
       "17377           1           1  0.26  0.2727  0.56     0.1343      13   \n",
       "17378           1           1  0.26  0.2727  0.65     0.1343      12   \n",
       "\n",
       "       registered  cnt  \n",
       "0              13   16  \n",
       "1              32   40  \n",
       "2              27   32  \n",
       "3              10   13  \n",
       "4               1    1  \n",
       "...           ...  ...  \n",
       "17374         108  119  \n",
       "17375          81   89  \n",
       "17376          83   90  \n",
       "17377          48   61  \n",
       "17378          37   49  \n",
       "\n",
       "[17379 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hour.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15114050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad8124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b61bab1-6888-48b2-ad1e-09737697ae28",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f615238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 0.0000e+00, 1.0000e+00, ..., 3.0000e+00, 1.3000e+01,\n",
       "        1.6000e+01],\n",
       "       [2.0000e+00, 0.0000e+00, 1.0000e+00, ..., 8.0000e+00, 3.2000e+01,\n",
       "        4.0000e+01],\n",
       "       [3.0000e+00, 0.0000e+00, 1.0000e+00, ..., 5.0000e+00, 2.7000e+01,\n",
       "        3.2000e+01],\n",
       "       ...,\n",
       "       [1.7377e+04, 7.3000e+02, 1.0000e+00, ..., 7.0000e+00, 8.3000e+01,\n",
       "        9.0000e+01],\n",
       "       [1.7378e+04, 7.3000e+02, 1.0000e+00, ..., 1.3000e+01, 4.8000e+01,\n",
       "        6.1000e+01],\n",
       "       [1.7379e+04, 7.3000e+02, 1.0000e+00, ..., 1.2000e+01, 3.7000e+01,\n",
       "        4.9000e+01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_date = pd.Timestamp('2011-01-01')\n",
    "df.iloc[:, 1] = (pd.to_datetime(df.iloc[:, 1]) - reference_date).dt.days\n",
    "data = df.to_numpy(dtype=float)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67ac9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 1.000e+00, 0.000e+00, ..., 2.879e-01, 8.100e-01,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 1.000e+00, 0.000e+00, ..., 2.727e-01, 8.000e-01,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 1.000e+00, 0.000e+00, ..., 2.727e-01, 8.000e-01,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [7.300e+02, 1.000e+00, 1.000e+00, ..., 2.576e-01, 6.000e-01,\n",
       "        1.642e-01],\n",
       "       [7.300e+02, 1.000e+00, 1.000e+00, ..., 2.727e-01, 5.600e-01,\n",
       "        1.343e-01],\n",
       "       [7.300e+02, 1.000e+00, 1.000e+00, ..., 2.727e-01, 6.500e-01,\n",
       "        1.343e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_whole = data[:, 1:14] # the first column is index, not necessary\n",
    "Y_whole = data[:, 16] # count of total rental bikes as label\n",
    "X_whole "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d631b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return (X-mean)/std, mean, std\n",
    "\n",
    "def split_train_test(X_whole, Y_whole, num=1500, rate=0.7):\n",
    "    # Shuffle data first\n",
    "    indices = jax.random.permutation(grab_prng(), X_whole.shape[0])\n",
    "    X_part = X_whole[indices]\n",
    "    Y_part = Y_whole[indices]\n",
    "    \n",
    "    indices = jax.random.permutation(grab_prng(), num)\n",
    "    X_shuffled = X_part[indices]\n",
    "    Y_shuffled = Y_part[indices]\n",
    "    \n",
    "    # Standardize the shuffled data\n",
    "    X, mean, std = standardize(X_shuffled)\n",
    "    Y, mean, std = standardize(Y_shuffled)\n",
    "\n",
    "    # Use the same indices for Y\n",
    "    # Y = Y_shuffled\n",
    "    \n",
    "    # Compute the split index\n",
    "    split_idx = int(num * rate)\n",
    "    \n",
    "    # Split indices into train and test\n",
    "    train_indices = indices[:split_idx]\n",
    "    test_indices = indices[split_idx:]\n",
    "    \n",
    "    # Split data using the indices\n",
    "    X_train = X[train_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01b07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(X_train, Y_train, seq_len=8):\n",
    "    n_samples = X_train.shape[0]\n",
    "    indices = jax.random.permutation(grab_prng(), n_samples)\n",
    "     # Shuffle the data\n",
    "    X_train_shuffled = X_train[indices]\n",
    "    Y_train_shuffled = Y_train[indices]\n",
    "    \n",
    "    # Calculate the base size of each subset\n",
    "    subset_size = n_samples // seq_len\n",
    "    remainder = n_samples % seq_len\n",
    "    \n",
    "    # Initialize lists to hold the subsets\n",
    "    X_seq = []\n",
    "    Y_seq = []\n",
    "    \n",
    "    start_idx = 0\n",
    "    for i in range(seq_len):\n",
    "        # The first subset gets the remainder (extra) samples\n",
    "        if i == 0:\n",
    "            end_idx = start_idx + subset_size + remainder\n",
    "        else:\n",
    "            end_idx = start_idx + subset_size\n",
    "        \n",
    "        X_seq.append(X_train_shuffled[start_idx:end_idx])\n",
    "        Y_seq.append(Y_train_shuffled[start_idx:end_idx])\n",
    "        \n",
    "        start_idx = end_idx\n",
    "    return X_seq, Y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a8a9eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.99977261, dtype=float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = split_train_test(X_whole, Y_whole, num=1500, rate=0.7)\n",
    "X_seq, Y_seq = split_sequence(X_train, Y_train, seq_len=8)\n",
    "\n",
    "np.std(X_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c4a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c95120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eece8ba-7932-4338-b9bb-1da218726f8a",
   "metadata": {},
   "source": [
    "# Hyperparameter initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053f909-8261-4872-9729-6f4e04231514",
   "metadata": {},
   "source": [
    "Note that, in the below initialization, it is assumed that noise variance is the first component, signal variance the second, and length scale the third. Feel free to modify if using pytrees.\n",
    "\n",
    "Further note: these are assumed constrained (strictly positive). You should map to unconstrained prior to running optimization, and map back to constrained when forming the GP posterior, and evaluating the predictive density for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de92ec2-abac-4905-9e75-0294b86194ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init_sqexp_hyperparams():\n",
    "    return np.array([jax.random.uniform(grab_prng(), minval=0.2, maxval=2),\n",
    "                     jax.random.uniform(grab_prng(), minval=0.2, maxval=2),\n",
    "                     X_train.shape[1]*jax.random.uniform(grab_prng(), minval=1, maxval=10)])\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b21180-e161-471e-b974-5af0442e297f",
   "metadata": {},
   "source": [
    "# Plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2b728b-22b4-49d4-a3da-fa1da6cb7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(lml_lpd):\n",
    "    plt.scatter(lml_lpd[:,0], lml_lpd[:,1])\n",
    "    \n",
    "    plt.xlabel('Log marginal likelihood')\n",
    "    plt.ylabel('Negative log predictive density')\n",
    "    plt.title('Is marginal likelihood a good indicator of generalization?')\n",
    "    plt.legend()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daacf8b-66f5-4922-a1ef-cfad27a2c1e5",
   "metadata": {},
   "source": [
    "# Experiment 1: Empirical Bayes for squared-exponential kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d07284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84862917-0610-406a-a1de-6caa919d17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_trials = 20\n",
    "# T = 200\n",
    "# step_size = 5e-4\n",
    "\n",
    "# gathered_trials = []\n",
    "# hyperparams_inits = []\n",
    "# for i in range(n_trials):\n",
    "#    hyperparams_inits.append(random_init_sqexp_hyperparams())\n",
    "\n",
    "# cov_func = sqexp_cov_function\n",
    "# X_star = X_test\n",
    "# for n in range(n_trials):\n",
    "#    hyperparams_init = hyperparams_inits[n]\n",
    "#    unconstrained_hyperparams_init = inverse_param_transform(hyperparams_init)\n",
    "   \n",
    "#    # sqexp_cov_function(X_train, X_train, unconstrained_hyperparams_init)\n",
    "   \n",
    "#    (unconstrained_hyperparams, lml) = empirical_bayes(cov_func, X_train, Y_train, unconstrained_hyperparams_init, step_size, T)\n",
    "#    hyperparams = param_transform(unconstrained_hyperparams)\n",
    "   \n",
    "#    posterior_predictive = gp_posterior(cov_func, X_train, Y_train, hyperparams_init)\n",
    "#    (posterior_mean, posterior_var) = posterior_predictive(X_star)\n",
    "#    neg_log_initial = neg_log_predictive_density(Y_test, posterior_mean, posterior_var, hyperparams_init[0])\n",
    "\n",
    "#    posterior_predictive = gp_posterior(cov_func, X_train, Y_train, hyperparams)\n",
    "#    (posterior_mean, posterior_var) = posterior_predictive(X_star)\n",
    "#    neg_log_final = neg_log_predictive_density(Y_test, posterior_mean, posterior_var, hyperparams[0])\n",
    "\n",
    "#    print(np.array([neg_log_initial, neg_log_final, lml]))\n",
    "#    gathered_trials.append(np.array([neg_log_initial, neg_log_final, lml]))\n",
    "# #\n",
    "# gathered_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a92d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials_array = np.array(gathered_trials)\n",
    "# lml_lpd = np.column_stack((trials_array[:, 2], trials_array[:, 1]))\n",
    "# scatterplot(lml_lpd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764acee6",
   "metadata": {},
   "source": [
    "# Dicsussion\n",
    "1. Negative log probability was consistently improved over the hyperparameters used at initialization, across all runs.\n",
    "2. According to the scatterplot above, we can see that as log marginal likelihood increases, negative log predicitive density on test set decreases at first, and increases later. Log marginal likelihood is a metric of our hyperparameters. The larger log marginal likelihood is, the better our hyperparameters are. But if they are better is determined by training set. Thus it's reasonable that \"better\" hyperparameters on training set don't always work better on test set. A large marginal likelihood may cause overfitting, although it works very well on training set. It's not a good indicator of generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c1238-32ba-4f43-94f7-962d8e350a01",
   "metadata": {},
   "source": [
    "# Experiment 2 - feature importance using learned Mahalanobis distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d8d5ee-5be9-4a80-a97a-4d7b93673d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use as your initial hyperparameters -> first two parameters are noise variance and signal variance,\n",
    "# remaining parameters are length scale; feel free to modify if using pytrees\n",
    "def random_init_sqexp_maha_hyperparams(X_train):\n",
    "    var = jax.random.uniform(grab_prng(), shape=(2,), minval=0.2, maxval=2)\n",
    "    length_scale = jax.random.uniform(grab_prng(), shape=(X_train.shape[1],), minval=1, maxval=10)\n",
    "    return np.concatenate([var, length_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d84d31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "cov_func = sqexp_cov_function\n",
    "X_star = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f75865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[541.26249812 211.00271935 630.10539939]\n",
      "[578.0239241  212.71638082 627.65256225]\n",
      "[556.05769763 220.07387107 626.89839933]\n",
      "[552.30320483 212.10770283 627.32564786]\n",
      "[618.85596229 221.24185629 633.4294511 ]\n",
      "[537.5318781  220.15495054 633.07564207]\n",
      "[663.2967781  209.84862045 639.8518874 ]\n"
     ]
    }
   ],
   "source": [
    "n_trials = 20\n",
    "T = 200\n",
    "step_size = 5e-4\n",
    "\n",
    "gathered_trials = []\n",
    "hyperparams_inits = []\n",
    "for i in range(n_trials):\n",
    "   hyperparams_inits.append(random_init_sqexp_maha_hyperparams(X_train))\n",
    "cov_func = sqexp_mahalanobis_cov_function\n",
    "X_star = X_test\n",
    "\n",
    "for n in range(n_trials):\n",
    "   hyperparams_init = hyperparams_inits[n]\n",
    "   unconstrained_hyperparams_init = inverse_param_transform(hyperparams_init)\n",
    "   (unconstrained_hyperparams, lml) = empirical_bayes(cov_func, X_train, Y_train, unconstrained_hyperparams_init, step_size, T)\n",
    "   hyperparams = param_transform(unconstrained_hyperparams)\n",
    "   \n",
    "   posterior_predictive = gp_posterior(cov_func, X_train, Y_train, hyperparams_init)\n",
    "   (posterior_mean, posterior_var) = posterior_predictive(X_star)\n",
    "   neg_log_initial = neg_log_predictive_density(Y_test, posterior_mean, posterior_var, hyperparams_init[0])\n",
    "\n",
    "   posterior_predictive = gp_posterior(cov_func, X_train, Y_train, hyperparams)\n",
    "   (posterior_mean, posterior_var) = posterior_predictive(X_star)\n",
    "   neg_log_final = neg_log_predictive_density(Y_test, posterior_mean, posterior_var, hyperparams[0])\n",
    "   print(np.array([neg_log_initial, neg_log_final, lml]))\n",
    "   gathered_trials.append(np.array([neg_log_initial, neg_log_final, lml]))\n",
    "#\n",
    "gathered_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6984be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_array = np.array(gathered_trials)\n",
    "lml_lpd = np.column_stack((trials_array[:, 2], trials_array[:, 1]))\n",
    "scatterplot(lml_lpd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
